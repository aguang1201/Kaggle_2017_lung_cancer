import tflearn
from tflearn.layers.core import input_data, dropout, fully_connected
from tflearn.layers.conv import conv_3d, max_pool_3d
from tflearn.layers.estimator import regression

def create_cnn_3d_network:
  # Building 'AlexNet'
  network = input_data(shape=[None, IMG_SIZE_PX, IMG_SIZE_PX, SLICE_COUNT, 1])
  network = conv_3d(network, 32, 3, [50, 50, 20])
  network = tf.activation(tflearn.batch_normalization(network),activation='relu')
  network = max_pool_3d(network, 3, strides=2)

  network = conv_3d(network, 64, 3, [25, 25, 10])
  network = tf.activation(tflearn.batch_normalization(network),activation='relu')
  network = max_pool_3d(network, 3, strides=2)

  network = conv_3d(network, 128, 3, [13, 13, 5])
  network = tf.activation(tflearn.batch_normalization(network),activation='relu')

  network = conv_3d(network, 256, 3, [13, 13, 5])
  network = tf.activation(tflearn.batch_normalization(network),activation='relu')
  network = max_pool_3d(network, 3, strides=2)

  network = fully_connected(network, 2048)
  network = tf.activation(tflearn.batch_normalization(network),activation='relu')
  network = dropout(network, keep_rate)

  network = fully_connected(network, 2048)
  network = tf.activation(tflearn.batch_normalization(network),activation='relu')
  network = dropout(network, keep_rate)

  network = fully_connected(network, n_classes)

  network = regression(network, optimizer='adam',
                       loss='softmax_categorical_crossentropy',
                       learning_rate=0.001)
                      
  return network                    
